{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90a51f10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 240, 256, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip3 install opencv-python\n",
    "\n",
    "from gym.wrappers import FrameStack, GrayScaleObservation\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import gym_super_mario_bros\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
    "\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "env= JoypadSpace(env, SIMPLE_MOVEMENT);\n",
    "\n",
    "env = GrayScaleObservation(env, keep_dim=True);\n",
    "env = DummyVecEnv([lambda: env])\n",
    "env = VecFrameStack(env, 4, channels_order='last')\n",
    "\n",
    "state = env.reset();\n",
    "state.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92b07ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path=save_path\n",
    "    \n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok =True)\n",
    "    \n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq ==0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "        return True;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "129991c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/'\n",
    "LOG_DIR = './logs/'\n",
    "\n",
    "callback = TrainAndLoggingCallback(check_freq = 100000, save_path= CHECKPOINT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f414c755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./logs/PPO_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 81  |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 6   |\n",
      "|    total_timesteps | 512 |\n",
      "----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 87           |\n",
      "|    total_timesteps      | 1024         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026590752 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | -0.00118     |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 92           |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    value_loss           | 214          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 9           |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 169         |\n",
      "|    total_timesteps      | 1536        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013808142 |\n",
      "|    clip_fraction        | 0.0576      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 8           |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 250         |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004005952 |\n",
      "|    clip_fraction        | 0.00117     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 3.4         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.000366   |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 7           |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 331         |\n",
      "|    total_timesteps      | 2560        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008136811 |\n",
      "|    clip_fraction        | 0.0459      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | 0.0461      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.295       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00461    |\n",
      "|    value_loss           | 1.45        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 7            |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 413          |\n",
      "|    total_timesteps      | 3072         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011724154 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | 0.407        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.211        |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | 0.00019      |\n",
      "|    value_loss           | 1.22         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 7            |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 493          |\n",
      "|    total_timesteps      | 3584         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061525693 |\n",
      "|    clip_fraction        | 0.0244       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.89        |\n",
      "|    explained_variance   | 0.543        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.171        |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00421     |\n",
      "|    value_loss           | 0.819        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 7            |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 576          |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036738606 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.9         |\n",
      "|    explained_variance   | 0.223        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.118        |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00074     |\n",
      "|    value_loss           | 0.727        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 7           |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 653         |\n",
      "|    total_timesteps      | 4608        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007930519 |\n",
      "|    clip_fraction        | 0.00996     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.0548      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.0876      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00588    |\n",
      "|    value_loss           | 0.449       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 7          |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 727        |\n",
      "|    total_timesteps      | 5120       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00477577 |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.92      |\n",
      "|    explained_variance   | -0.000702  |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 0.108      |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.00402   |\n",
      "|    value_loss           | 0.532      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 7           |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 803         |\n",
      "|    total_timesteps      | 5632        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015264317 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.027       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.126       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.381       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 882          |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030264067 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.88        |\n",
      "|    explained_variance   | -0.0447      |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.0713       |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00211     |\n",
      "|    value_loss           | 0.278        |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 967         |\n",
      "|    total_timesteps      | 6656        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002381351 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | -0.000566   |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.0396      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.000895   |\n",
      "|    value_loss           | 0.156       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 1048         |\n",
      "|    total_timesteps      | 7168         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033374273 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.89        |\n",
      "|    explained_variance   | -0.0322      |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.0432       |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.002       |\n",
      "|    value_loss           | 0.147        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 1123         |\n",
      "|    total_timesteps      | 7680         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014681955 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.9         |\n",
      "|    explained_variance   | -0.0158      |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.0592       |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.000809    |\n",
      "|    value_loss           | 0.164        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 1200         |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045534167 |\n",
      "|    clip_fraction        | 0.0082       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.89        |\n",
      "|    explained_variance   | -0.00914     |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.0522       |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00589     |\n",
      "|    value_loss           | 0.122        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 1275        |\n",
      "|    total_timesteps      | 8704        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008255962 |\n",
      "|    clip_fraction        | 0.0785      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.0178      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 43.4        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | 0.00164     |\n",
      "|    value_loss           | 158         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 1354         |\n",
      "|    total_timesteps      | 9216         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0109017175 |\n",
      "|    clip_fraction        | 0.0318       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.8         |\n",
      "|    explained_variance   | 0.199        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 31.9         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | 0.00385      |\n",
      "|    value_loss           | 132          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 1425        |\n",
      "|    total_timesteps      | 9728        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011779631 |\n",
      "|    clip_fraction        | 0.048       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | 0.785       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.489       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00572    |\n",
      "|    value_loss           | 2.6         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 1497         |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039871796 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.81        |\n",
      "|    explained_variance   | 0.748        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.519        |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    value_loss           | 2.13         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 1568         |\n",
      "|    total_timesteps      | 10752        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009858132 |\n",
      "|    clip_fraction        | 0.00352      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.84        |\n",
      "|    explained_variance   | 0.656        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.307        |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | 0.000238     |\n",
      "|    value_loss           | 1.44         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 1639         |\n",
      "|    total_timesteps      | 11264        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044085425 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.83        |\n",
      "|    explained_variance   | -0.124       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.375        |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00168     |\n",
      "|    value_loss           | 1.23         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 1710        |\n",
      "|    total_timesteps      | 11776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012344323 |\n",
      "|    clip_fraction        | 0.073       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | -0.0145     |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.248       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00982    |\n",
      "|    value_loss           | 0.881       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 1781        |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004508431 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | 0.177       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.261       |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00257    |\n",
      "|    value_loss           | 0.848       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 1852        |\n",
      "|    total_timesteps      | 12800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011649813 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.183       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 0.571       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 1923        |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009848066 |\n",
      "|    clip_fraction        | 0.00527     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | 0.00563     |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.203       |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00451    |\n",
      "|    value_loss           | 0.444       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 2003         |\n",
      "|    total_timesteps      | 13824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033884605 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.85        |\n",
      "|    explained_variance   | -0.00325     |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.186        |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.000922    |\n",
      "|    value_loss           | 0.337        |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-02b91602c837>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPPO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CnnPolicy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard_log\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOG_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done learning'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    297\u001b[0m     ) -> \"PPO\":\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         return super(PPO, self).learn(\n\u001b[0m\u001b[1;32m    300\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0;31m# Optimization step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m                 \u001b[0;31m# Clip grad norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!pip install tensorboard\n",
    "model = PPO('CnnPolicy', env, verbose =1, tensorboard_log=LOG_DIR, learning_rate=0.00001, n_steps=512)\n",
    "\n",
    "model.learn(total_timesteps=1000000, callback=callback)\n",
    "print('done learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b5a818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = PPO.load('./train/best_model_10000')\n",
    "# state=env.reset();\n",
    "# while True:\n",
    "#     action,_state = model.predict(state)\n",
    "#     state, reward, done, info = env.step(action)\n",
    "#     env.render();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
